{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7f147d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id category_name recorded_date  is_active  \\\n",
      "0   1     sunscreen    2023-09-06          1   \n",
      "\n",
      "                                        category_url extra_field1  \\\n",
      "0  https://www.amazon.in/gp/bestsellers/beauty/10...         None   \n",
      "\n",
      "  extra_field2 extra_field3 extra_field4 extra_field5  project_identifier_id  \n",
      "0         None         None         None         None                      1  \n",
      "after printing category_df >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "1\n",
      "after printing category_id >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeus\\AppData\\Local\\Temp\\ipykernel_23092\\316734758.py:138: FutureWarning: Calling int on a single element Series is deprecated and will raise a TypeError in the future. Use int(ser.iloc[0]) instead\n",
      "  category_id = int(category['id'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "after printing category_id >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "1\n",
      "after printing category_id >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "wrote to db >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from urllib.request import urlopen, Request\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# import pangres\n",
    "\n",
    "proxies = {\n",
    "    \"http\": \"http://125.141.200.53:80\",\n",
    "    \"https\": \"https://125.141.200.53:80\",\n",
    "    \"ftp\": \"ftp://10.10.1.10:3128\"\n",
    "}\n",
    "\n",
    "proxies_list = [\"128.199.109.241:8080\",\"113.53.230.195:3128\",\"125.141.200.53:80\",\"125.141.200.14:80\",\"128.199.200.112:138\",\"149.56.123.99:3128\",\"128.199.200.112:80\",\"125.141.200.39:80\",\"134.213.29.202:4444\"]\n",
    "\n",
    "\n",
    "engine = sqlalchemy.create_engine('postgresql://postgres:pass@localhost:5432/glenmark')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# \n",
    "# Variables for finding components of soup\n",
    "# \n",
    "\n",
    "tag_name_for_product_div = \"div\"\n",
    "attribute_for_product_div = {\"class\": 'a-cardui _cDEzb_grid-cell_1uMOS expandableGrid p13n-grid-content'}\n",
    "\n",
    "tag_name_for_product_name = \"div\"\n",
    "attribute_for_product_name = {\"class\": '_cDEzb_p13n-sc-css-line-clamp-3_g3dy1'}\n",
    "\n",
    "tag_name_for_product_name2 = \"div\"\n",
    "attribute_for_product_name2 = {\"class\": '_cDEzb_p13n-sc-css-line-clamp-4_2q2cc'}\n",
    "\n",
    "tag_name_for_product_rank = \"span\"\n",
    "attribute_for_product_rank = {\"class\": 'zg-bdg-text'}\n",
    "\n",
    "# \n",
    "# End of variables\n",
    "# \n",
    "\n",
    "\n",
    "\n",
    "# Function for creating soup object\n",
    "# Takes one url as an input and returns soup of that page\n",
    "def get_soup(url):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "#     driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "    html_content = driver.page_source\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    driver.quit()\n",
    "    return soup\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetch_data(url, category_id, pincode):\n",
    "    product_name_list = []\n",
    "    product_rank_list = []\n",
    "    \n",
    "    soup = get_soup(url)\n",
    "#     print(soup)\n",
    "\n",
    "    product_divs = soup.find_all(tag_name_for_product_div, attribute_for_product_div)\n",
    "    \n",
    "    for product in product_divs:\n",
    "        try:\n",
    "            product_name = product.find(tag_name_for_product_name, attribute_for_product_name).text.strip()\n",
    "        except Exception as e:\n",
    "            product_name = product.find(tag_name_for_product_name2, attribute_for_product_name2).text.strip()\n",
    "            \n",
    "        product_name_list.append(product_name)\n",
    "        \n",
    "        product_rank = product.find(tag_name_for_product_rank, attribute_for_product_rank).text.replace(\"#\", \"\").strip()\n",
    "        product_rank_list.append(product_rank)\n",
    "                    \n",
    "    crawl_date = date.today()\n",
    "        \n",
    "    products_df = pd.DataFrame({'crawl_date': crawl_date,\n",
    "                               'product_name': product_name_list,\n",
    "                               'product_rank': product_rank_list,\n",
    "                               'bestseller_category_id': category_id,\n",
    "                               'area_id': pincode})\n",
    "    \n",
    "    return products_df\n",
    "#     print(products_df)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def bestseller_rank():\n",
    "    try:\n",
    "        query = text('select * from \"product_bestsellercategory\" where \"is_active\"=:val1 and \"project_identifier_id\"=:val2')\n",
    "        params = {'val1':1, 'val2':1}\n",
    "        category_df = pd.read_sql_query(query, engine, params=params)\n",
    "        print(category_df)\n",
    "        print(\"after printing category_df >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "        \n",
    "        query = text('select * from \"product_area\"')\n",
    "        area_df = pd.read_sql_query(query, engine, params=params)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"after printing e in bestseller_rank 1st except >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "        \n",
    "    try:\n",
    "        products_df = pd.DataFrame()\n",
    "        \n",
    "        for pincode in area_df['pincode']:\n",
    "        \n",
    "            for url in category_df['category_url']:\n",
    "\n",
    "                # To append category_id, fetching respective category_id from the category_df\n",
    "                category = category_df[category_df['category_url']==url]\n",
    "                category_id = int(category['id'])\n",
    "                print(category_id)\n",
    "                print(\"after printing category_id >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "\n",
    "                count = 1\n",
    "                while count < 3:\n",
    "                    df = fetch_data(url +str(count), category_id, pincode)\n",
    "                    count = count + 1\n",
    "                    products_df = pd.concat([products_df, df])\n",
    "                    \n",
    "                    \n",
    "        products_df.to_sql('product_amazonbestsellerrank', engine, if_exists='append', index=False)\n",
    "        print(\"wrote to db >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "                \n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"after printing e in bestseller_rank 2nd except >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "bestseller_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758f1a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
