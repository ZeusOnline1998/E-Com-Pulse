{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88b80db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-05\n",
      "[datetime.date(2023, 9, 5)]\n",
      "['15']\n",
      "[' #27 in Sunscreen']\n",
      "[411045]\n",
      "KATALYSST Yes\n",
      "790\n",
      "672.00\n",
      "5224\n",
      "3187\n",
      "1254\n",
      "470\n",
      "157\n",
      "209\n",
      "[3187, 1254, 470, 157, 209]\n",
      "1\n",
      " Buy  More   673.00 \n",
      "   platform_id  product_id  area_id  crawl_date  seller_name main_seller  \\\n",
      "0            1           1   411045  2023-09-05    KATALYSST         Yes   \n",
      "1            1           1   411045  2023-09-05   Buy  More           No   \n",
      "\n",
      "    price promo  availability overall_rating    bestseller_rank  \\\n",
      "0  672.00    15             1            4.4   #27 in Sunscreen   \n",
      "1   673.0    14             1            4.4   #27 in Sunscreen   \n",
      "\n",
      "  product_weight total_ratings  five_stars_rating  four_stars_rating  \\\n",
      "0           50 g          5224               3187               1254   \n",
      "1           50 g          5224               3187               1254   \n",
      "\n",
      "   three_stars_rating  two_stars_rating  one_star_rating  \n",
      "0                 470               157              209  \n",
      "1                 470               157              209  \n",
      "[datetime.date(2023, 9, 5)]\n",
      "['50 g']\n",
      "[]\n",
      "['Not Applicable']\n",
      "[411045]\n",
      "['KWTRADERS']\n",
      "['Yes']\n",
      "['549']\n",
      "[1]\n",
      "['589']\n",
      "https://www.flipkart.com/la-shield-spf-40-pa/product-reviews/itm2652ae3334815?pid=SNRGC3HMGYHNMZKS&lid=LSTSNRGC3HMGYHNMZKSKQ6URE&marketplace=FLIPKART\n",
      "   platform_id  product_id  area_id  crawl_date seller_name main_seller price  \\\n",
      "0            2           2   411045  2023-09-05   KWTRADERS         Yes   549   \n",
      "\n",
      "  promo  availability overall_rating bestseller_rank product_weight  \\\n",
      "0   20%             1            3.9  Not Applicable           50 g   \n",
      "\n",
      "  total_ratings five_stars_rating four_stars_rating three_stars_rating  \\\n",
      "0           589               318               102                 41   \n",
      "\n",
      "  two_stars_rating one_star_rating  \n",
      "0               20             108  \n",
      "['La Shield Sunscreen Gel SPF 40 PA+++']\n",
      "['50gm']\n",
      "[datetime.date(2023, 9, 5)]\n",
      "['15%']\n",
      "['Nykaa E retail private limited']\n",
      "['672']\n",
      "['1']\n",
      "['8454']\n",
      "   platform_id  product_id  area_id  crawl_date  \\\n",
      "0            3           3   411045  2023-09-05   \n",
      "\n",
      "                      seller_name main_seller price promo availability  \\\n",
      "0  Nykaa E retail private limited         N/A   672   15%            1   \n",
      "\n",
      "  overall_rating bestseller_rank product_weight total_ratings  \\\n",
      "0            4.5  Not Applicable           50gm          8454   \n",
      "\n",
      "  five_stars_rating four_stars_rating three_stars_rating two_stars_rating  \\\n",
      "0              5935              1473                456              196   \n",
      "\n",
      "  one_star_rating  \n",
      "0             394  \n",
      "   platform_id  product_id  area_id  crawl_date  \\\n",
      "0            1           1   411045  2023-09-05   \n",
      "1            1           1   411045  2023-09-05   \n",
      "0            2           2   411045  2023-09-05   \n",
      "0            3           3   411045  2023-09-05   \n",
      "\n",
      "                      seller_name main_seller   price promo availability  \\\n",
      "0                       KATALYSST         Yes  672.00    15            1   \n",
      "1                      Buy  More           No   673.0    14            1   \n",
      "0                       KWTRADERS         Yes     549   20%            1   \n",
      "0  Nykaa E retail private limited         N/A     672   15%            1   \n",
      "\n",
      "  overall_rating    bestseller_rank product_weight total_ratings  \\\n",
      "0            4.4   #27 in Sunscreen           50 g          5224   \n",
      "1            4.4   #27 in Sunscreen           50 g          5224   \n",
      "0            3.9     Not Applicable           50 g           589   \n",
      "0            4.5     Not Applicable           50gm          8454   \n",
      "\n",
      "  five_stars_rating four_stars_rating three_stars_rating two_stars_rating  \\\n",
      "0              3187              1254                470              157   \n",
      "1              3187              1254                470              157   \n",
      "0               318               102                 41               20   \n",
      "0              5935              1473                456              196   \n",
      "\n",
      "  one_star_rating  \n",
      "0             209  \n",
      "1             209  \n",
      "0             108  \n",
      "0             394  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from urllib.request import urlopen, Request\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "# import pangres\n",
    "\n",
    "\n",
    "proxies = {\n",
    "    \"http\": \"http://125.141.200.53:80\",\n",
    "    \"https\": \"https://125.141.200.53:80\",\n",
    "    \"ftp\": \"ftp://10.10.1.10:3128\"\n",
    "}\n",
    "\n",
    "proxies_list = [\"128.199.109.241:8080\",\"113.53.230.195:3128\",\"125.141.200.53:80\",\"125.141.200.14:80\",\"128.199.200.112:138\",\"149.56.123.99:3128\",\"128.199.200.112:80\",\"125.141.200.39:80\",\"134.213.29.202:4444\"]\n",
    "\n",
    "engine = sqlalchemy.create_engine('postgresql://postgres:postgres@localhost:5432/glenmark')\n",
    "\n",
    "\n",
    "\n",
    "# for amazon_scraping()\n",
    "tag_name_for_product_weight = 'div'\n",
    "attributes_for_product_weight = {\"id\": \"variation_size_name\"}\n",
    "\n",
    "tag_name_for_product_weight_text = 'span'\n",
    "class_for_product_weight_text = \"selection\"\n",
    "\n",
    "tag_name_for_product_promos1 = 'span'\n",
    "class_for_product_promos1 = \"a-size-large a-color-price savingPriceOverride aok-align-center reinventPriceSavingsPercentageMargin savingsPercentage\"\n",
    "\n",
    "tag_name_for_product_promos2 = 'td'\n",
    "class_for_product_promos2 = \"a-span12 a-color-price a-size-base\"\n",
    "\n",
    "tag_name_for_product_promos2_text = 'span'\n",
    "class_for_product_promos2_text = \"a-color-price\"\n",
    "\n",
    "tag_name_for_product_bestseller_rank = 'ul'\n",
    "class_for_product_bestseller_rank = \"a-unordered-list a-nostyle a-vertical zg_hrsr\"\n",
    "\n",
    "tag_name_for_product_bestseller_rank_text = 'span'\n",
    "class_for_product_bestseller_rank_text = \"a-list-item\"\n",
    "\n",
    "tag_name_for_main_seller_name = 'div'\n",
    "attributes_for_main_seller_name = {\"id\": \"merchant-info\"}\n",
    "\n",
    "tag_name_for_mrp = 'span'\n",
    "attributes_for_mrp = {'class':'a-price a-text-price a-size-base'}\n",
    "\n",
    "tag_name_for_price = 'span'\n",
    "attributes_for_price = {\"class\": \"a-offscreen\"}\n",
    "\n",
    "tag_name_for_stock = 'span'\n",
    "class_for_stock = \"a-size-medium a-color-success\"\n",
    "\n",
    "tag_name_for_product_rating = 'span'\n",
    "attributes_for_product_rating = {\"data-hook\": \"rating-out-of-text\"}\n",
    "\n",
    "tag_name_for_total_ratings = 'span'\n",
    "attributes_for_total_ratings = {\"id\": 'acrCustomerReviewText'}\n",
    "\n",
    "tag_name_for_all_ratings = 'tr'\n",
    "class_for_all_ratings = \"a-histogram-row a-align-center\"\n",
    "\n",
    "tag_name_for_individual_rating = 'a'\n",
    "class_for_individual_rating = \"a-link-normal\"\n",
    "\n",
    "tag_name_for_other_sellers = 'div'\n",
    "class_for_other_sellers = \"a-box mbc-offer-row pa_mbc_on_amazon_offer\"\n",
    "\n",
    "tag_name_for_other_seller_name = 'span'\n",
    "class_for_other_seller_name = \"a-size-small mbcMerchantName\"\n",
    "\n",
    "tag_name_for_other_seller_price = 'span'\n",
    "\n",
    "\n",
    "# for flipkart_scraping()\n",
    "fl_tag_name_for_product_name = \"span\"\n",
    "fl_class_for_product_name = \"B_NuCI\"\n",
    "\n",
    "fl_tag_name_for_product_weight = \"table\"\n",
    "fl_class_for_product_weight = \"_14cfVK\"\n",
    "\n",
    "fl_tag_name_for_product_weight_text = 'li'\n",
    "fl_class_for_product_weight_text = \"_21lJbe\"\n",
    "\n",
    "fl_tag_name_for_product_promos = 'div'\n",
    "fl_class_for_product_promos = \"_3Ay6Sb _31Dcoz\"\n",
    "\n",
    "fl_tag_name_for_pincode = 'input'\n",
    "fl_class_for_pincode = \"_36yFo0\"\n",
    "\n",
    "fl_tag_name_for_main_seller_name = 'div'\n",
    "fl_attributes_for_main_seller_name = {\"id\": \"sellerName\"}\n",
    "\n",
    "fl_tag_name_for_price = 'div'\n",
    "fl_class_for_price = \"_30jeq3 _16Jk6d\"\n",
    "\n",
    "fl_tag_name_for_stock = 'div'\n",
    "fl_class_for_stock = \"_16FRp0\"\n",
    "\n",
    "fl_tag_name_for_product_rating = 'div'\n",
    "fl_class_for_product_rating = \"_3LWZlK\"\n",
    "\n",
    "fl_tag_name_for_total_ratings = 'span'\n",
    "fl_class_for_total_ratings = \"_2_R_DZ\"\n",
    "\n",
    "fl_tag_name_for_ratings_count_url = 'div'\n",
    "fl_class_for_ratings_count_url = \"col JOpGWq _33R3aa\"\n",
    "\n",
    "fl_tag_name_for_ratings_count = 'div'\n",
    "fl_class_for_ratings_count = \"_1uJVNT\"\n",
    "\n",
    "fl_tag_name_for_other_seller_names = 'div'\n",
    "fl_class_for_other_seller_names = \"_3enH42\"\n",
    "\n",
    "fl_tag_name_for_other_seller_price = 'div'\n",
    "fl_class_for_other_seller_price = '_30jeq3'\n",
    "\n",
    "fl_tag_name_for_other_seller_promos = 'div'\n",
    "fl_class_for_other_seller_promos = '_3Ay6Sb'\n",
    "\n",
    "\n",
    "# for nykaa_scraping()\n",
    "ny_tag_name_for_product_name = \"h1\"\n",
    "ny_class_for_product_name = \"css-1gc4x7i\"\n",
    "\n",
    "ny_tag_name_for_product_promos = 'span'\n",
    "ny_class_for_product_promos = \"css-bhhehx\"\n",
    "\n",
    "ny_tag_name_for_main_seller_name = 'span'\n",
    "ny_class_for_main_seller_name = \"css-1ggqzsv\"\n",
    "\n",
    "ny_tag_name_for_product_rating = 'div'\n",
    "ny_class_for_product_rating = \"css-m6n3ou\"\n",
    "\n",
    "ny_tag_name_for_price = 'span'\n",
    "ny_class_for_price = \"css-1jczs19\"\n",
    "\n",
    "ny_tag_name_for_total_ratings = 'div'\n",
    "ny_class_for_total_ratings = \"css-1hvvm95\"\n",
    "\n",
    "ny_tag_name_for_all_ratings = 'span'\n",
    "ny_class_for_all_ratings = \"css-11lfsnj\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function for creating soup object\n",
    "# Takes one url as an input and returns soup of that page\n",
    "def get_soup(url):\n",
    "    header = {'User-Agent': 'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.71 Safari/537.36'}\n",
    "    req = Request(url, headers=header)\n",
    "    Response = urlopen(req, timeout=time.sleep(0.5 * random.random()))\n",
    "    soup = BeautifulSoup(Response, 'html.parser')\n",
    "    time.sleep(1.5 * random.random())\n",
    "    return soup\n",
    "\n",
    "\n",
    "# This method takes product url as an input and fetches product details\n",
    "# Product details are stored in a dataframe\n",
    "def amazon_scraping(url, pincode, product_id):\n",
    "    Product_id = []\n",
    "    crawl_date = []\n",
    "    Promos = []\n",
    "    Bestseller_rank = []\n",
    "    Product_weight = []\n",
    "    Pincode = []\n",
    "    Seller = []\n",
    "    Main_seller = []\n",
    "    Price = []\n",
    "    In_stock = []\n",
    "    Overall_product_rating = []\n",
    "    Total_ratings = []\n",
    "    Rating_1 = []\n",
    "    Rating_2 = []\n",
    "    Rating_3 = []\n",
    "    Rating_4 = []\n",
    "    Rating_5 = []\n",
    "    Rating = []\n",
    "\n",
    "\n",
    "    soup = get_soup(url)\n",
    "#     print(soup)\n",
    "\n",
    "    Product_id.append(product_id)\n",
    "\n",
    "    today_date = date.today()\n",
    "    print(today_date)\n",
    "    crawl_date.append(today_date)\n",
    "    print(crawl_date)\n",
    "    \n",
    "    try:\n",
    "        product_weight = soup.find(tag_name_for_product_weight, attributes_for_product_weight)\n",
    "        product_weight = product_weight.find(tag_name_for_product_weight_text, class_=class_for_product_weight_text).text\n",
    "        product_weight = product_weight.splitlines()[1].split(\"(\")[0].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        product_weight = \"\"\n",
    "    Product_weight.append(product_weight)\n",
    "#     print(Product_weight)\n",
    "\n",
    "    try:\n",
    "        promos = soup.find(tag_name_for_product_promos1, class_=class_for_product_promos1)\n",
    "        promos = promos.text.replace(\"-\", \"\")\n",
    "        promos = promos.replace(\"%\", \"\").strip()\n",
    "    except (ValueError, AttributeError):\n",
    "        promos = soup.find(tag_name_for_product_promos2, class_=class_for_product_promos2).find(tag_name_for_product_promos2_text, class_=class_for_product_promos2_text).text\n",
    "        promos = promos.split(\"(\")[1]\n",
    "        promos = promos.replace(\")\", \"\")\n",
    "        promos = promos.replace(\"%\", \"\").strip()\n",
    "    Promos.append(promos)\n",
    "    print(Promos)\n",
    "\n",
    "    try:\n",
    "        bestseller_rank = soup.find(tag_name_for_product_bestseller_rank, class_=class_for_product_bestseller_rank).find(tag_name_for_product_bestseller_rank_text, class_=class_for_product_bestseller_rank_text).text\n",
    "    except (ValueError):\n",
    "        bestseller_rank = \"\"\n",
    "    Bestseller_rank.append(bestseller_rank)\n",
    "    print(Bestseller_rank)\n",
    "\n",
    "    Pincode.append(pincode)\n",
    "    print(Pincode)\n",
    "\n",
    "    try:\n",
    "        main_seller_name = soup.find(tag_name_for_main_seller_name, attributes_for_main_seller_name).find_all(\"span\")[1].text\n",
    "        main_seller = \"Yes\"\n",
    "        Main_seller.append(main_seller)\n",
    "    except (ValueError):\n",
    "        main_seller_name = \"\"\n",
    "    print(main_seller_name + \" \" + main_seller)\n",
    "    Seller.append(main_seller_name)\n",
    "\n",
    "    try:\n",
    "        mrp = soup.find_all(tag_name_for_mrp, attributes_for_mrp)[0].text\n",
    "        mrp = mrp.split(\"₹\")[1].strip()\n",
    "        print(mrp)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    try:\n",
    "        price = soup.find_all(tag_name_for_price, attributes_for_price)[0].text\n",
    "        price = price.replace(\"₹\", \"\").strip()\n",
    "    except (ValueError, IndexError):\n",
    "        price = None\n",
    "    print(price)\n",
    "    Price.append(price)\n",
    "\n",
    "    try:\n",
    "        stock = soup.find(tag_name_for_stock, class_=class_for_stock).text\n",
    "        if(lower(stock)==\"in stock\"):\n",
    "            stock = 1\n",
    "        else:\n",
    "            stock = 0\n",
    "    except:\n",
    "        stock = 1\n",
    "    In_stock.append(stock)\n",
    "    \n",
    "    try:\n",
    "        product_rating = soup.find(tag_name_for_product_rating, attributes_for_product_rating)\n",
    "        product_rating = product_rating.text.split()[0].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        product_rating = None\n",
    "    Overall_product_rating.append(product_rating)\n",
    "    \n",
    "    try:\n",
    "        total_ratings = soup.find_all(tag_name_for_total_ratings, attributes_for_total_ratings)[0]\n",
    "        total_ratings = total_ratings.text.split()[0].strip()\n",
    "        if \",\" in total_ratings:\n",
    "            total_ratings = total_ratings.replace(\",\",\"\")\n",
    "    except:\n",
    "        total_ratings = ''\n",
    "    print(total_ratings)\n",
    "    Total_ratings.append(total_ratings)\n",
    "\n",
    "    try:\n",
    "        ratings = soup.find_all(tag_name_for_all_ratings, class_=class_for_all_ratings)\n",
    "        for i in range(0, 5):\n",
    "            rating = ratings[i].find_all(tag_name_for_individual_rating, class_=class_for_individual_rating)[2]\n",
    "            rating = rating.text.splitlines()[2].strip()\n",
    "            rating = rating.replace(\"%\",\"\").strip()\n",
    "            rating = round((int(rating) * int(total_ratings)) / 100)\n",
    "            print(rating)\n",
    "            Rating.append(rating)\n",
    "        Rating_5.append(Rating[0])\n",
    "        Rating_4.append(Rating[1])\n",
    "        Rating_3.append(Rating[2])\n",
    "        Rating_2.append(Rating[3])\n",
    "        Rating_1.append(Rating[4])\n",
    "    except:\n",
    "        Rating_5.append('')\n",
    "        Rating_4.append('')\n",
    "        Rating_3.append('')\n",
    "        Rating_2.append('')\n",
    "        Rating_1.append('')\n",
    "    print(Rating)\n",
    "\n",
    "    try:\n",
    "        other_sellers = soup.find_all(tag_name_for_other_sellers, class_=class_for_other_sellers)\n",
    "        print(len(other_sellers))\n",
    "        for i in range(0, len(other_sellers)):\n",
    "            other_seller_name = soup.find_all(tag_name_for_other_seller_name, class_=class_for_other_seller_name)[i].text\n",
    "            try:\n",
    "                price = soup.find(tag_name_for_other_seller_price, {\"id\": \"mbc-price-\" + str(i + 1)}).text\n",
    "            except (ValueError, IndexError, AttributeError):\n",
    "                price = None\n",
    "            price = price.replace(\"₹\", \"\")\n",
    "            print(other_seller_name + \" \" + price)\n",
    "            main_seller = \"No\"\n",
    "            \n",
    "            mrp = float(mrp)\n",
    "            price = float(price)\n",
    "            promos = int(((mrp-price)/mrp)*100)\n",
    "\n",
    "            crawl_date.append(today_date)\n",
    "            Promos.append(promos)\n",
    "            Bestseller_rank.append(bestseller_rank)\n",
    "            Pincode.append(pincode)\n",
    "            Seller.append(other_seller_name)\n",
    "            Main_seller.append(main_seller)\n",
    "            Price.append(price)\n",
    "            In_stock.append(stock)\n",
    "            Overall_product_rating.append(product_rating)\n",
    "            Product_id.append(product_id)\n",
    "            Product_weight.append(product_weight)\n",
    "            Total_ratings.append(total_ratings)\n",
    "            Rating_5.append(Rating[0])\n",
    "            Rating_4.append(Rating[1])\n",
    "            Rating_3.append(Rating[2])\n",
    "            Rating_2.append(Rating[3])\n",
    "            Rating_1.append(Rating[4])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        other_sellers = \"\"\n",
    "\n",
    "    df = pd.DataFrame({\"platform_id\": 1,\n",
    "                       \"product_id\": Product_id,\n",
    "                       \"area_id\": Pincode,\n",
    "                       \"crawl_date\": crawl_date,\n",
    "                       \"seller_name\": Seller,\n",
    "                       \"main_seller\": Main_seller,\n",
    "                       \"price\": Price,\n",
    "                       \"promo\": Promos,\n",
    "                       \"availability\": In_stock,\n",
    "                       \"overall_rating\": Overall_product_rating,\n",
    "                       \"bestseller_rank\": Bestseller_rank,\n",
    "                      \"product_weight\": Product_weight,\n",
    "                       \"total_ratings\": Total_ratings,\n",
    "                       \"five_stars_rating\": Rating_5,\n",
    "                       \"four_stars_rating\": Rating_4,\n",
    "                       \"three_stars_rating\": Rating_3,\n",
    "                       \"two_stars_rating\": Rating_2,\n",
    "                       \"one_star_rating\": Rating_1,})\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# This method takes product url as an input and fetches product details\n",
    "# Product details are stored in a dataframe\n",
    "def flipkart_scraping(url, pincode, product_id):\n",
    "    Fl_Product_id = []\n",
    "    Fl_crawl_date = []\n",
    "    Fl_Promos = []\n",
    "    Fl_Bestseller_rank = []\n",
    "    Fl_Pincode = []\n",
    "    Fl_Seller = []\n",
    "    Fl_Main_seller = []\n",
    "    Fl_Price = []\n",
    "    Fl_In_stock = []\n",
    "    Fl_Overall_product_rating = []\n",
    "    Fl_Product_weight = []\n",
    "    Fl_Total_ratings = []\n",
    "    Fl_Rating_1 = []\n",
    "    Fl_Rating_2 = []\n",
    "    Fl_Rating_3 = []\n",
    "    Fl_Rating_4 = []\n",
    "    Fl_Rating_5 = []\n",
    "    Fl_Rating = []\n",
    "    \n",
    "    soup = get_soup(url)\n",
    "    \n",
    "    Fl_Product_id.append(product_id)\n",
    "\n",
    "    today_date = date.today()\n",
    "    Fl_crawl_date.append(today_date)\n",
    "    print(Fl_crawl_date)\n",
    "    \n",
    "    try:\n",
    "        product_weight = soup.find_all(fl_tag_name_for_product_weight, class_=fl_class_for_product_weight)[1]\n",
    "        product_weight = product_weight.find_all(fl_tag_name_for_product_weight_text, class_=fl_class_for_product_weight_text)[2].text\n",
    "    except:\n",
    "        product_weight = soup.find(fl_tag_name_for_product_weight, class_=fl_class_for_product_weight)\n",
    "        product_weight = product_weight.find_all(fl_tag_name_for_product_weight_text, class_=fl_class_for_product_weight_text)[0].text\n",
    "    Fl_Product_weight.append(product_weight)\n",
    "    print(Fl_Product_weight)\n",
    "    \n",
    "\n",
    "    try:\n",
    "        promos = soup.find(fl_tag_name_for_product_promos, class_=fl_class_for_product_promos).text.split()[0]\n",
    "    except (ValueError, IndexError, AttributeError):\n",
    "        promos = \"\"\n",
    "#     Fl_Promos.append(promos)\n",
    "    print(Fl_Promos)\n",
    "\n",
    "    bestseller_rank = \"Not Applicable\"\n",
    "    Fl_Bestseller_rank.append(bestseller_rank)\n",
    "    print(Fl_Bestseller_rank)\n",
    "\n",
    "    Fl_Pincode.append(pincode)\n",
    "    print(Fl_Pincode)\n",
    "\n",
    "    try:\n",
    "        seller = soup.find(fl_tag_name_for_main_seller_name, fl_attributes_for_main_seller_name)\n",
    "        seller = seller.find(\"span\").find(\"span\").text\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        seller = ''\n",
    "    Fl_Seller.append(seller)\n",
    "    print(Fl_Seller)\n",
    "    Fl_Main_seller.append(\"Yes\")\n",
    "    print(Fl_Main_seller)\n",
    "\n",
    "    try:\n",
    "        price = soup.find(fl_tag_name_for_price, class_=fl_class_for_price).text\n",
    "        price = price.replace(\"₹\", \"\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        price = None\n",
    "    Fl_Price.append(price)\n",
    "    print(Fl_Price)\n",
    "\n",
    "    try:\n",
    "        in_stock = soup.find(fl_tag_name_for_stock, class_=fl_class_for_stock).text.strip()\n",
    "        if(lower(in_stock)=='sold out'):\n",
    "            in_stock = 0\n",
    "        else:\n",
    "            in_stock = 1\n",
    "    except:\n",
    "        in_stock = 1\n",
    "    Fl_In_stock.append(in_stock)\n",
    "    print(Fl_In_stock)\n",
    "\n",
    "    try:\n",
    "        product_rating = soup.find_all(fl_tag_name_for_product_rating, fl_class_for_product_rating)[0]\n",
    "        product_rating = product_rating.text.strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        product_rating = None\n",
    "    Fl_Overall_product_rating.append(product_rating)\n",
    "    \n",
    "    try:\n",
    "        total_ratings = soup.find_all(fl_tag_name_for_total_ratings, class_=fl_class_for_total_ratings)[0]\n",
    "        total_ratings = total_ratings.find(\"span\").find(\"span\").text\n",
    "        total_ratings = total_ratings.split()[0]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        total_ratings = \"\"\n",
    "    Fl_Total_ratings.append(total_ratings)\n",
    "    print(Fl_Total_ratings)\n",
    "    \n",
    "    if total_ratings == \"\":\n",
    "        Fl_Rating.append(\"\")\n",
    "        Fl_Rating.append(\"\")\n",
    "        Fl_Rating.append(\"\")\n",
    "        Fl_Rating.append(\"\")\n",
    "        Fl_Rating.append(\"\")\n",
    "    else:\n",
    "        try:\n",
    "            # For fetching individual count of ratings\n",
    "            ratings_count_url = soup.find(fl_tag_name_for_ratings_count_url, class_=fl_class_for_ratings_count_url).find_all(\"a\")[3]\n",
    "            ratings_count_url = \"https://www.flipkart.com\" + str(ratings_count_url['href'])\n",
    "            print(ratings_count_url)\n",
    "\n",
    "            ratings_count_soup = get_soup(ratings_count_url)\n",
    "\n",
    "            ratings_count = ratings_count_soup.find_all(fl_tag_name_for_ratings_count, class_=fl_class_for_ratings_count)\n",
    "            for rating in ratings_count:\n",
    "                Fl_Rating.append(rating.text)\n",
    "        except Exception as e:\n",
    "            Fl_Rating.append(\"\")\n",
    "            Fl_Rating.append(\"\")\n",
    "            Fl_Rating.append(\"\")\n",
    "            Fl_Rating.append(\"\")\n",
    "            Fl_Rating.append(\"\")\n",
    "\n",
    "    Fl_Rating_5.append(Fl_Rating[0])\n",
    "    Fl_Rating_4.append(Fl_Rating[1])\n",
    "    Fl_Rating_3.append(Fl_Rating[2])\n",
    "    Fl_Rating_2.append(Fl_Rating[3])\n",
    "    Fl_Rating_1.append(Fl_Rating[4])\n",
    "    \n",
    "\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.get(url)\n",
    "    link_other_sellers = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CSS_SELECTOR, 'li._38I6QT')))\n",
    "    link_other_sellers = link_other_sellers.find_element(By.TAG_NAME, 'a')\n",
    "    link_other_sellers.click()\n",
    "    time.sleep(2)\n",
    "    html_content = driver.page_source\n",
    "    other_seller_soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    driver.quit()\n",
    "\n",
    "    other_seller_names = other_seller_soup.find_all(fl_tag_name_for_other_seller_names, class_=fl_class_for_other_seller_names)\n",
    "    for name in other_seller_names:\n",
    "        if name == other_seller_names[0]:\n",
    "            pass\n",
    "        else:\n",
    "            Fl_Seller.append(name.text)\n",
    "            Fl_Main_seller.append(\"No\")\n",
    "            Fl_In_stock.append(\"1\")\n",
    "\n",
    "    other_seller_prices = other_seller_soup.find_all(fl_tag_name_for_other_seller_price, class_=fl_class_for_other_seller_price)\n",
    "    for price in other_seller_prices:\n",
    "        if price == other_seller_prices[0]:\n",
    "            pass\n",
    "        else:\n",
    "            Fl_Price.append(price.text.replace(\"₹\",\"\"))\n",
    "            Fl_crawl_date.append(today_date)\n",
    "            Fl_Bestseller_rank.append(bestseller_rank)\n",
    "            Fl_Pincode.append(pincode)\n",
    "            Fl_Overall_product_rating.append(product_rating)\n",
    "            Fl_Product_id.append(product_id)\n",
    "            Fl_Product_weight.append(product_weight)\n",
    "            Fl_Total_ratings.append(total_ratings)\n",
    "            Fl_Rating_5.append(Fl_Rating[0])\n",
    "            Fl_Rating_4.append(Fl_Rating[1])\n",
    "            Fl_Rating_3.append(Fl_Rating[2])\n",
    "            Fl_Rating_2.append(Fl_Rating[3])\n",
    "            Fl_Rating_1.append(Fl_Rating[4])\n",
    "    try:\n",
    "        other_seller_promos = other_seller_soup.find_all(fl_tag_name_for_other_seller_promos, class_=fl_class_for_other_seller_promos)\n",
    "        if len(other_seller_promos) == len(other_seller_names):\n",
    "            for promo in other_seller_promos:\n",
    "                Fl_Promos.append(promo.text.split()[0])\n",
    "        else:\n",
    "            count = abs(len(other_seller_names) - len(other_seller_promos))\n",
    "            for promo in other_seller_promos:\n",
    "                Fl_Promos.append(promo.text.split()[0])\n",
    "            var = 1\n",
    "            while var <= count:\n",
    "                Fl_Promos.append(\"No\")\n",
    "                var += 1\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        for other_seller in other_seller_names:\n",
    "            Fl_Promos.append(\"No\")\n",
    "            \n",
    "            \n",
    "    df = pd.DataFrame({\"platform_id\": 2,\n",
    "                       \"product_id\": Fl_Product_id,\n",
    "                       \"area_id\": Fl_Pincode,\n",
    "                       \"crawl_date\": Fl_crawl_date,\n",
    "                       \"seller_name\": Fl_Seller,\n",
    "                       \"main_seller\": Fl_Main_seller,\n",
    "                       \"price\": Fl_Price,\n",
    "                       \"promo\": Fl_Promos,\n",
    "                       \"availability\": Fl_In_stock,\n",
    "                       \"overall_rating\": Fl_Overall_product_rating,\n",
    "                       \"bestseller_rank\": Fl_Bestseller_rank,\n",
    "                      \"product_weight\": Fl_Product_weight,\n",
    "                      \"total_ratings\": Fl_Total_ratings,\n",
    "                       \"five_stars_rating\": Fl_Rating_5,\n",
    "                       \"four_stars_rating\": Fl_Rating_4,\n",
    "                       \"three_stars_rating\": Fl_Rating_3,\n",
    "                       \"two_stars_rating\": Fl_Rating_2,\n",
    "                       \"one_star_rating\": Fl_Rating_1})\n",
    "\n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# This method takes product url as an input and fetches product details\n",
    "# Product details are stored in a dataframe\n",
    "def nykaa_scraping(url, pincode, product_id):\n",
    "    Ny_Product_id = []\n",
    "    Ny_Product_name = []\n",
    "    Ny_crawl_date = []\n",
    "    Ny_Promos = []\n",
    "    Ny_Pincode = []\n",
    "    Ny_Seller = []\n",
    "    Ny_Price = []\n",
    "    Ny_In_stock = []\n",
    "    Ny_Product_weight = []\n",
    "    Ny_Overall_product_rating = []\n",
    "    Ny_Total_ratings = []\n",
    "    Ny_Rating_1 = []\n",
    "    Ny_Rating_2 = []\n",
    "    Ny_Rating_3 = []\n",
    "    Ny_Rating_4 = []\n",
    "    Ny_Rating_5 = []\n",
    "    Ny_Rating = []\n",
    "\n",
    "    soup = get_soup(url)\n",
    "    \n",
    "    Ny_Product_id.append(product_id)\n",
    "    \n",
    "    try:\n",
    "        complete_product_name = soup.find(ny_tag_name_for_product_name, class_=ny_class_for_product_name).text\n",
    "        product_name = complete_product_name.split(\"(\")[0]\n",
    "        product_weight = complete_product_name.split(\"(\")[1]\n",
    "        product_weight = product_weight.replace(\")\", \"\")\n",
    "    except (ValueError, IndexError):\n",
    "        product_name = \"\"\n",
    "        product_weight = \"\"\n",
    "    Ny_Product_name.append(product_name)\n",
    "    print(Ny_Product_name)\n",
    "    Ny_Product_weight.append(product_weight)\n",
    "    print(Ny_Product_weight)\n",
    "\n",
    "    today_date = date.today()\n",
    "    Ny_crawl_date.append(today_date)\n",
    "    print(Ny_crawl_date)\n",
    "\n",
    "    try:\n",
    "        promos = soup.find_all(ny_tag_name_for_product_promos, class_=ny_class_for_product_promos)[0]\n",
    "        promos = promos.text.split()[0]\n",
    "    except (ValueError, IndexError):\n",
    "        promos = \"\"\n",
    "    Ny_Promos.append(promos)\n",
    "    print(Ny_Promos)\n",
    "\n",
    "    pincode = pincode\n",
    "    Ny_Pincode.append(pincode)\n",
    "\n",
    "    seller_name = soup.find(ny_tag_name_for_main_seller_name, class_=ny_class_for_main_seller_name)\n",
    "    Ny_Seller.append(seller_name.text)\n",
    "    print(Ny_Seller)\n",
    "\n",
    "    try:\n",
    "        price = soup.find_all(ny_tag_name_for_price, class_=ny_class_for_price)[0]\n",
    "        price = price.text.replace(\"₹\", \"\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        price = None\n",
    "    Ny_Price.append(price)\n",
    "    print(Ny_Price)\n",
    "\n",
    "    in_stock = \"1\"\n",
    "    Ny_In_stock.append(in_stock)\n",
    "    print(Ny_In_stock)\n",
    "\n",
    "    try:\n",
    "        product_rating = soup.find(ny_tag_name_for_product_rating, ny_class_for_product_rating).text\n",
    "        product_rating = product_rating.split(\"/\")[0].strip()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        product_rating = None\n",
    "    Ny_Overall_product_rating.append(product_rating)\n",
    "    \n",
    "    try:\n",
    "        total_ratings = soup.find_all(ny_tag_name_for_total_ratings, class_=ny_class_for_total_ratings)[0]\n",
    "        total_ratings = total_ratings.text.split()[0]\n",
    "    except (ValueError, IndexError):\n",
    "        total_ratings = \"\"\n",
    "    Ny_Total_ratings.append(total_ratings)\n",
    "    print(Ny_Total_ratings)\n",
    "\n",
    "    try:\n",
    "        ratings = soup.find_all(ny_tag_name_for_all_ratings, class_=ny_class_for_all_ratings)\n",
    "        for rating in ratings:\n",
    "            Ny_Rating.append(rating.text)\n",
    "        Ny_Rating_5.append(Ny_Rating[0])\n",
    "        Ny_Rating_4.append(Ny_Rating[1])\n",
    "        Ny_Rating_3.append(Ny_Rating[2])\n",
    "        Ny_Rating_2.append(Ny_Rating[3])\n",
    "        Ny_Rating_1.append(Ny_Rating[4])\n",
    "    except (IndexError, ValueError):\n",
    "        Ny_Rating_5.append(\"\")\n",
    "        Ny_Rating_4.append(\"\")\n",
    "        Ny_Rating_3.append(\"\")\n",
    "        Ny_Rating_2.append(\"\")\n",
    "        Ny_Rating_1.append(\"\")\n",
    "#     print(Ny_Rating_1)\n",
    "#     print(Ny_Rating_2)\n",
    "#     print(Ny_Rating_3)\n",
    "#     print(Ny_Rating_4)\n",
    "#     print(Ny_Rating_5)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame({\"platform_id\": 3,\n",
    "                   \"product_id\": Ny_Product_id,\n",
    "                   \"area_id\": Ny_Pincode,\n",
    "                   \"crawl_date\": Ny_crawl_date,\n",
    "                   \"seller_name\": Ny_Seller,\n",
    "                   \"main_seller\": \"N/A\",\n",
    "                   \"price\": Ny_Price,\n",
    "                   \"promo\": Ny_Promos,\n",
    "                   \"availability\": Ny_In_stock,\n",
    "                   \"overall_rating\": Ny_Overall_product_rating,\n",
    "                   \"bestseller_rank\": \"Not Applicable\",\n",
    "                  \"product_weight\": Ny_Product_weight,\n",
    "                  \"total_ratings\": Ny_Total_ratings,\n",
    "                   \"five_stars_rating\": Ny_Rating_5,\n",
    "                   \"four_stars_rating\": Ny_Rating_4,\n",
    "                   \"three_stars_rating\": Ny_Rating_3,\n",
    "                   \"two_stars_rating\": Ny_Rating_2,\n",
    "                   \"one_star_rating\": Ny_Rating_1,})\n",
    "    \n",
    "    \n",
    "    print(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def product_details():\n",
    "    try:\n",
    "        query = text('select * from \"crawldata_product\" where \"is_active\"=:val1')\n",
    "        params = {'val1':1}\n",
    "        products_df = pd.read_sql_query(query, engine, params=params)\n",
    "#         print(products_df)\n",
    "#         print(\"after products_df >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    amazon_products_df = products_df[products_df['platform_id']==1]\n",
    "    flipkart_products_df = products_df[products_df['platform_id']==2]\n",
    "    nykaa_products_df = products_df[products_df['platform_id']==3]\n",
    "#     print(amazon_products_df)\n",
    "#     print(flipkart_products_df)\n",
    "#     print(nykaa_products_df)\n",
    "#     print(\"after df >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "    \n",
    "    \n",
    "#     Crawling product details from Amazon\n",
    "    try:\n",
    "        for url in amazon_products_df['product_url']:\n",
    "            single_product_df = amazon_products_df[amazon_products_df['product_url']==url]\n",
    "#             print(single_product_df)\n",
    "#             print(\"after single_product_df >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "\n",
    "            query = text('select * from \"crawldata_productarea\" where \"product_id\"=:val1')\n",
    "            product_id = single_product_df['id'][0]\n",
    "#             print(product_id)\n",
    "#             print(\"after product_id >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "            params = {'val1':int(product_id)}\n",
    "            areas_df = pd.read_sql_query(query, engine, params=params)\n",
    "#             print(areas_df)\n",
    "#             print(\"after areas_df >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "            \n",
    "            for pincode in areas_df['area_id']:\n",
    "                returned_df = amazon_scraping(url, pincode, product_id)\n",
    "                combined_df = pd.concat([combined_df, returned_df])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "        \n",
    "#     Crawling product details from Flipkart\n",
    "    try:\n",
    "        for url in flipkart_products_df['product_url']:\n",
    "            single_product_df = flipkart_products_df[flipkart_products_df['product_url']==url]\n",
    "            single_product_df = single_product_df.reset_index(drop=True)\n",
    "#             print(single_product_df)\n",
    "#             print(\"after single_product_df >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "\n",
    "            query = text('select * from \"crawldata_productarea\" where \"product_id\"=:val1')\n",
    "            product_id = single_product_df['id'][0]\n",
    "#             print(product_id)\n",
    "#             print(\"after product_id >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "            params = {'val1':int(product_id)}\n",
    "            areas_df = pd.read_sql_query(query, engine, params=params)\n",
    "#             print(areas_df)\n",
    "#             print(\"after areas_df >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "            \n",
    "            for pincode in areas_df['area_id']:\n",
    "                returned_df = flipkart_scraping(url, pincode, product_id)\n",
    "                combined_df = pd.concat([combined_df, returned_df])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "\n",
    "#     Crawling product details from Nykaa\n",
    "    try:\n",
    "        for url in nykaa_products_df['product_url']:\n",
    "            single_product_df = nykaa_products_df[nykaa_products_df['product_url']==url]\n",
    "            single_product_df = single_product_df.reset_index(drop=True)\n",
    "#             print(single_product_df)\n",
    "#             print(\"after single_product_df >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "\n",
    "            query = text('select * from \"crawldata_productarea\" where \"product_id\"=:val1')\n",
    "            product_id = single_product_df['id'][0]\n",
    "#             print(product_id)\n",
    "#             print(\"after product_id >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "            params = {'val1':int(product_id)}\n",
    "            areas_df = pd.read_sql_query(query, engine, params=params)\n",
    "#             print(areas_df)\n",
    "#             print(\"after areas_df >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "            \n",
    "            for pincode in areas_df['area_id']:\n",
    "                returned_df = nykaa_scraping(url, pincode, product_id)\n",
    "                combined_df = pd.concat([combined_df, returned_df])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "#     combined_df.to_sql('crawldata_productdetails', engine, if_exists='append', index=False)\n",
    "    print(combined_df)\n",
    "        \n",
    "product_details()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3168ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bdc6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af5f99a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
